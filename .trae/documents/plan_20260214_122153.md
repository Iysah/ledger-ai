I will update the `sendMessage` function in `src/services/ai/inference.ts` to improve the prompt engineering as requested.

The changes involve:
1.  Defining `currentDate` to assist with relative date parsing.
2.  Refactoring the prompt into a structured `systemPrompt` and `userPrompt`.
3.  Updating the `llm.generate` call to pass both the system and user messages.

```typescript
    const categoriesList = PREDEFINED_CATEGORIES.map(c => c.name).join(', ');
    const currentDate = new Date().toISOString().split('T')[0];

    const systemPrompt = `
    You are a specialized Financial Data Extraction engine for a private ledger.
    Your ONLY goal is to parse user text into a structured JSON schema.

    CONTEXT:
    - Today's Date: ${currentDate}
    - Valid Categories: [${categoriesList}]

    RULES:
    1. Classification: Determine if the input is an 'entry' (logging an expense) or a 'query' (asking for information).
    2. Normalization:
       - Always convert relative dates (e.g., "yesterday", "last Friday") to YYYY-MM-DD based on Today's Date.
       - If a category doesn't perfectly match, map it to the closest 'Valid Category'. If no match is even remote, use 'Uncategorized'.
    3. Data Integrity:
       - Amounts must be pure numbers.
       - If the user mentions a merchant like "Starbucks", extract it. If not, set to null.
    4. Response Format: Return ONLY valid JSON. No conversational text, no markdown blocks.
    `;

    const userPrompt = `Input: "${text}"`;

    await llm.generate([
      { role: 'system', content: systemPrompt },
      { role: 'user', content: userPrompt }
    ]);
```